import csv
import itertools
import speech_recognition as sr
import sys

from os import listdir, mkdir
from os.path import basename, dirname, isfile, join, splitext

from pydub import AudioSegment
from pydub.silence import detect_nonsilent, split_on_silence

# settings for voa
KEEP_SILENCE=500
MIN_SILENCE_LEN=1000
SEEK_STEP=1

def split_utterance(utt_id, utt_loc):
    """
    This function splits an utterance based on silence regions via Pydub.
    Criteria for determining when to split are defined by three variables:

    MIN_SILENCE_LEN - minimum silence duration
    SEEK_STEP       - distance between the beginning of consecutive analysis
        frames
    silence_thresh  - maximum silence energy, dependent on the RMS value of the
        utterance, in dBFS

    Parameters
    ----------
    utt_id : string
    Utterance ID, used for naming the speech chunks that will be produced from
    splitting
    utt_loc : string
    Path of the utterance to be split

    Returns
    -------
    chunk_locs : list
    List of the locations of all speech chunks defined after segmentation

    """
    utt_dir = dirname(utt_loc)
    utt_ext = splitext(utt_loc)[1]
    chunks_dir = utt_dir + "/chunks"

    chunk_locs = list()

    try:
        mkdir(chunks_dir)
    except(FileExistsError):
        pass

    speech_data = getattr(AudioSegment, "from_" + utt_ext[1:])(utt_loc)

    # Silence defined based on RMS
    # VoA: minus 30 derived empirically, specifically
    # to accommodate words ending in unvoiced fricatives (e.g., /s/)
    silence_thresh = speech_data.dBFS - 30

    # Get timestamps of speech chunks to be used for filename generation
    chunk_times = detect_nonsilent(
        speech_data, 
        min_silence_len=MIN_SILENCE_LEN,
        silence_thresh=silence_thresh,
        seek_step=SEEK_STEP
    )

    # Speech chunks defined are padded by silence dictated by KEEP_SILENCE
    chunks = split_on_silence(
        speech_data, 
        min_silence_len=MIN_SILENCE_LEN,
        silence_thresh=silence_thresh,
        keep_silence=KEEP_SILENCE,
        seek_step=SEEK_STEP
    )

    for chunk_time, chunk in zip(chunk_times, chunks):
        chunk_id = f"{utt_id}-{str(round(chunk_time[0]/10)).zfill(5)}-{str(round(chunk_time[1]/10)).zfill(5)}"
        chunk_loc = f"{chunks_dir}/{chunk_id}{utt_ext}"

        chunk.export(chunk_loc, format=utt_ext[1:])
        chunk_locs.append(chunk_loc)

    return chunk_locs


def transcribe_from_list(wav_scp_file, sr_out_file, split=False):
    """
    This function transcribes a set of recordings listed in a text file. The
    text file follows the format of Kaldi's wav.scp file. Each line corresponds
    to an utterance,referred to by its ID and location. The format of each line
    is as follows:

    <utterance_ID> <utterance_location>

    The utterance_ID is specified to facilitate the calculation of the word
    error rate (WER) later on.

    Parameters
    ----------
    wav_scp_file : string
    Path of the text file containing the list of recordings to be processed. If
    this was generated by Kaldi, it will usually be named as wav.scp, thus the
    parameter name.

    sr_out_file : string
    Path of the text file where the speech recognizer outputs will be stored.
    Each row of the text file corresponds to one utterance with the following
    format:

    <utterance_ID> <recognizer_hypothesis>

    Returns
    -------
    None

    """
    original_stdout = sys.stdout

    with open(sr_out_file, 'w') as sr_out_f:
        with open(wav_scp_file, 'r') as wav_in_f:
            for entry in wav_in_f:
                utt_id,utt_loc = entry.strip().split(" ", maxsplit=1)

                if split:
                    sr_partials = list()
                    print(
                        f"{sys.argv[0]}: Splitting utterance "
                        f"{utt_id} into chunks..."
                    )
                    chunk_locs = split_utterance(utt_id, utt_loc)
                    print("Done.")

                    print(
                        f"{sys.argv[0]}: Deriving hypothesis "
                        f"for utterance {utt_id}..."
                    )
                    for chunk_loc in chunk_locs:
                        chunk_id = basename(chunk_loc).split(".")[0]

                        sr_partial = transcribe_utterance(chunk_id, chunk_loc)
                        sr_partials.append(sr_partial.upper() + ".")

                    sr_output = " ".join(sr_partials)

                else:
                    print(
                        f"{sys.argv[0]}: Deriving hypothesis "
                        f"for utterance {utt_id}..."
                    )
                    sr_output = transcribe_utterance(utt_id, utt_loc)

                sys.stdout = sr_out_f
                print(f"{utt_id} {sr_output}")
                sys.stdout = original_stdout
                print("Done.")

def transcribe_utterance(utt_id, utt_loc):
    """
    Run an utterance through the speech recognizer in the Google Web Speech API

    Parameters
    ----------
    utt_id : string
    Utterance ID, used to refer to the utterance to be recognized
    utt_loc : string
    Path of the utterance to be recognized

    Returns
    -------
    sr_output : string
    Speech recognizer's hypothesis. An empty string is returned if the 
    utterance wasn't processed

    """
    sr.output = ""
    r = sr.Recognizer()

    speech_file = sr.AudioFile(utt_loc)

    with speech_file as source:
        speech_data = r.record(source)

    try:
        sr_output = r.recognize_google(speech_data).upper()
        sr_output = sr_output.upper()
        return sr_output

    except sr.UnknownValueError:
        print(f"{sys.argv[0]}: Could not process {utt_id}.")
        return ""

def main():
    is_split = True     # files are split into chunks before transcription

    wav_scp_file = ""   # list of utterances to be transcribed
                        # line format is <utterance_ID> <utterance_location>
    sr_out_file = ""    # output file for recognizer hypotheses

    transcribe_from_list(wav_scp_file, sr_out_file, split=is_split)

if __name__ == "__main__":
    main()
